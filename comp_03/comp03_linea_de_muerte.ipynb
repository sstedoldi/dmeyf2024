{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emulación de Línea de Muerte\n",
    "\n",
    "- Undersampleo del dataset preprocesado de comp03_fe6_6xx\n",
    "- Entrenamiento de 34 semillas tomando la optmización bayesiana de un colega de comisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /home/santtedo/.venv/lib/python3.12/site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/santtedo/.venv/lib/python3.12/site-packages (from imbalanced-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/santtedo/.venv/lib/python3.12/site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/santtedo/.venv/lib/python3.12/site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/santtedo/.venv/lib/python3.12/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/santtedo/.venv/lib/python3.12/site-packages (from imbalanced-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: dask[dataframe] in /home/santtedo/.venv/lib/python3.12/site-packages (2024.10.0)\n",
      "Requirement already satisfied: click>=8.1 in /home/santtedo/.venv/lib/python3.12/site-packages (from dask[dataframe]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /home/santtedo/.venv/lib/python3.12/site-packages (from dask[dataframe]) (3.1.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/santtedo/.venv/lib/python3.12/site-packages (from dask[dataframe]) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/santtedo/.venv/lib/python3.12/site-packages (from dask[dataframe]) (24.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in /home/santtedo/.venv/lib/python3.12/site-packages (from dask[dataframe]) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/santtedo/.venv/lib/python3.12/site-packages (from dask[dataframe]) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/santtedo/.venv/lib/python3.12/site-packages (from dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: pandas>=2.0 in /home/santtedo/.venv/lib/python3.12/site-packages (from dask[dataframe]) (2.2.3)\n",
      "Requirement already satisfied: dask-expr<1.2,>=1.1 in /home/santtedo/.venv/lib/python3.12/site-packages (from dask[dataframe]) (1.1.16)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /home/santtedo/.venv/lib/python3.12/site-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (17.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/santtedo/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/santtedo/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/santtedo/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/santtedo/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
      "Requirement already satisfied: locket in /home/santtedo/.venv/lib/python3.12/site-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/santtedo/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "!pip install dask[dataframe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgbm\n",
    "\n",
    "#######\n",
    "# rutas\n",
    "# datasets\n",
    "from config import dataset_file_fe6_6xxpqt, dataset_file_fe6_6xxpqt_under # con lag1&2 + delta1&2\n",
    "      \n",
    "# optimizacion\n",
    "from config import db_path\n",
    "# modelos\n",
    "from config import modelos_path\n",
    "# predicciones\n",
    "from config import pred_path\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignorar advertencias de tipo UserWarning\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='pandas')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "semillas = [437809, 327347, 392879, 455783, 217163]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(dataset_file_fe6_6xxpqt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampleo con bajas unificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201912, 201908, 201901, 202104, 202101, 202005, 202007, 202001,\n",
       "       201905, 202002, 201903, 201906, 202102, 202006, 202011, 202008,\n",
       "       201902, 201907, 202103, 202105, 201911, 202107, 202012, 202003,\n",
       "       201910, 202106, 201904, 202009, 202010, 202004, 201909])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unificación de bajas\n",
    "data['clase_binaria'] = 0\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria'] == 'BAJA+2', 1, 0)\n",
    "\n",
    "# quitando meses sin clase \n",
    "meses_excluidos = [202108, 202109] # meses con clase ternaria incompleta\n",
    "data = data[~data['foto_mes'].isin(meses_excluidos)]\n",
    "data['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se retienen 2494 de la clase mayoritaria y 4 de la minoritaria\n",
      "Se retienen 2502 de la clase mayoritaria y 688 de la minoritaria\n",
      "Se retienen 2513 de la clase mayoritaria y 760 de la minoritaria\n",
      "Se retienen 2528 de la clase mayoritaria y 579 de la minoritaria\n",
      "Se retienen 2539 de la clase mayoritaria y 660 de la minoritaria\n",
      "Se retienen 2571 de la clase mayoritaria y 608 de la minoritaria\n",
      "Se retienen 2600 de la clase mayoritaria y 689 de la minoritaria\n",
      "Se retienen 2642 de la clase mayoritaria y 552 de la minoritaria\n",
      "Se retienen 2674 de la clase mayoritaria y 576 de la minoritaria\n",
      "Se retienen 2721 de la clase mayoritaria y 624 de la minoritaria\n",
      "Se retienen 2758 de la clase mayoritaria y 735 de la minoritaria\n",
      "Se retienen 2801 de la clase mayoritaria y 598 de la minoritaria\n",
      "Se retienen 2869 de la clase mayoritaria y 502 de la minoritaria\n",
      "Se retienen 2938 de la clase mayoritaria y 185 de la minoritaria\n",
      "Se retienen 2979 de la clase mayoritaria y 378 de la minoritaria\n",
      "Se retienen 2986 de la clase mayoritaria y 533 de la minoritaria\n",
      "Se retienen 3012 de la clase mayoritaria y 629 de la minoritaria\n",
      "Se retienen 3062 de la clase mayoritaria y 624 de la minoritaria\n",
      "Se retienen 3104 de la clase mayoritaria y 542 de la minoritaria\n",
      "Se retienen 3131 de la clase mayoritaria y 472 de la minoritaria\n",
      "Se retienen 3156 de la clase mayoritaria y 564 de la minoritaria\n",
      "Se retienen 3184 de la clase mayoritaria y 488 de la minoritaria\n",
      "Se retienen 3201 de la clase mayoritaria y 646 de la minoritaria\n",
      "Se retienen 3217 de la clase mayoritaria y 634 de la minoritaria\n",
      "Se retienen 3224 de la clase mayoritaria y 785 de la minoritaria\n",
      "Se retienen 3232 de la clase mayoritaria y 1017 de la minoritaria\n",
      "Se retienen 3254 de la clase mayoritaria y 981 de la minoritaria\n",
      "Se retienen 3258 de la clase mayoritaria y 1189 de la minoritaria\n",
      "Se retienen 3274 de la clase mayoritaria y 911 de la minoritaria\n",
      "Se retienen 3276 de la clase mayoritaria y 1074 de la minoritaria\n",
      "Se retienen 3277 de la clase mayoritaria y 1294 de la minoritaria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(111498, 946)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subsampled = []\n",
    "\n",
    "for mes, group in data.groupby(\"foto_mes\"):\n",
    "\n",
    "    X = group.drop(columns=\"clase_binaria\")\n",
    "    y = group[\"clase_binaria\"]\n",
    "    \n",
    "    # Calculo la proporcion de bajas\n",
    "    minority_proportion = y.value_counts(normalize=True).get(1, 0)\n",
    "    \n",
    "    # voy a incrementar esa proporcion por 10\n",
    "\n",
    "    estrategia={0: int(len(y[y == 0]) * 0.02), \n",
    "                1: len(y[y == 1])}\n",
    "\n",
    "    print(f\"Se retienen {estrategia[0]} de la clase mayoritaria y {estrategia[1]} de la minoritaria\")\n",
    "    \n",
    "    # new_proportion = minority_proportion * 10\n",
    "\n",
    "    rus = RandomUnderSampler(sampling_strategy=estrategia, random_state=semillas[0])\n",
    "    X_res, y_res = rus.fit_resample(X, y)\n",
    "\n",
    "    # Rearmar\n",
    "    group_resampled = pd.concat([X_res, y_res], axis=1)\n",
    "    group_resampled[\"foto_mes\"] = mes\n",
    "\n",
    "    df_subsampled.append(group_resampled)\n",
    "\n",
    "# Mergear\n",
    "data = pd.concat(df_subsampled, ignore_index=True)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo por las dudas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet(dataset_file_fe6_6xxpqt_under, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
       "       201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
       "       202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
       "       202101, 202102, 202103, 202104, 202105, 202106, 202107])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para recordar los periodos en los que entrenamos el modelo final:\n",
    "data['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111498, 946)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos pesos a las clases\n",
    "\n",
    "data['clase_peso'] = 1.0\n",
    "\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_binaria'] = 0\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria'] == 'CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with all NaN values: ['payroll_slope_1_foto_mes', 'cuenta_corriente_slope_1_foto_mes', 'visa_consumo_slope_1_foto_mes', 'comisiones_mantenimiento_slope_1_foto_mes', 'comisiones_otras_slope_1_foto_mes']\n"
     ]
    }
   ],
   "source": [
    "X_train = data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria'], axis=1)\n",
    "\n",
    "# Imputacion de Xs\n",
    "cols_with_all_nan = X_train.columns[X_train.isna().all()].tolist()\n",
    "print(\"Columns with all NaN values:\", cols_with_all_nan)\n",
    "X_train = X_train.drop(columns=cols_with_all_nan)\n",
    "\n",
    "# Imputación de nulls\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_train_imp = pd.DataFrame(imp_median.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Codificar variables categóricas\n",
    "categorical_features = [col for col in X_train_imp.columns if X_train_imp[col].dtype == 'object']\n",
    "\n",
    "# Convertir variables categóricas a 'category' dtype para LightGBM\n",
    "for col in categorical_features:\n",
    "    X_train_imp[col] = X_train_imp[col].astype('category')\n",
    "\n",
    "y_train_binaria = data['clase_binaria'] # Junta a los 2 baja\n",
    "w_train = data['clase_peso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejores parametros\n",
    "\n",
    "Tomadas de la optmización bayesiana de un compañero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 470, 'learning_rate': 0.0068, 'min_data_in_leaf': 305, 'feature_fraction': 0.31, 'bagging_fraction': 0.12, 'n_jobs': -1, 'objective': 'binary', 'boosting_type': 'gbdt', 'first_metric_only': True, 'boost_from_average': True, 'feature_pre_filter': False, 'max_bin': 31, 'verbose': -1}\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 470,\n",
    "            'learning_rate': 0.0068,\n",
    "            'min_data_in_leaf': 305,\n",
    "            'feature_fraction': 0.31, # tengo mas variables\n",
    "            'bagging_fraction': 0.12} # subo apenas este param\n",
    "\n",
    "params.update({'n_jobs': -1,\n",
    "                'objective': 'binary',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'first_metric_only': True,\n",
    "                'boost_from_average': True,\n",
    "                'feature_pre_filter': False,\n",
    "                'max_bin': 31,\n",
    "                'verbose': -1\n",
    "               })\n",
    "\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos a predecir para Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vuelvo a leer sin undersamplear\n",
    "data_ = pd.read_parquet(dataset_file_fe6_6xxpqt)\n",
    "\n",
    "mes_test = 202109\n",
    "\n",
    "X_kaggle = data_[data_['foto_mes'] == mes_test]\n",
    "X_kaggle = X_kaggle.drop(columns=['clase_ternaria']) # nulls\n",
    "\n",
    "del data_\n",
    "\n",
    "# prepro en X:kaggle\n",
    "X_kaggle = X_kaggle.drop(columns=cols_with_all_nan)\n",
    "X_kaggle_imp = pd.DataFrame(imp_median.transform(X_kaggle), columns=X_train.columns)\n",
    "for col in categorical_features:\n",
    "    X_kaggle_imp[col] = X_kaggle_imp[col].astype('category')\n",
    "\n",
    "numero_de_cliente = X_kaggle_imp['numero_de_cliente'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entranmiento con semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running semillerío para entrega\n",
      "{'num_leaves': 470, 'learning_rate': 0.0068, 'min_data_in_leaf': 305, 'feature_fraction': 0.31, 'bagging_fraction': 0.12, 'n_jobs': -1, 'objective': 'binary', 'boosting_type': 'gbdt', 'first_metric_only': True, 'boost_from_average': True, 'feature_pre_filter': False, 'max_bin': 31, 'verbose': -1}\n",
      "Entrenando modelo con semilla: 217170, 1 de 34\n"
     ]
    }
   ],
   "source": [
    "print(\"Running semillerío para entrega\")\n",
    "print(params)\n",
    "\n",
    "# para registrar las probabilidades\n",
    "df_sem_proba = pd.DataFrame({\n",
    "                            'client': numero_de_cliente.values,\n",
    "                        })\n",
    "\n",
    "j = 0\n",
    "s_r = range(217163, 455783, 7*7*7*7*3) # 34 semillas\n",
    "# s_r = list(range(2)) # 2 semillas de prueba\n",
    "\n",
    "s_total = len(list(s_r))\n",
    "for s in s_r:\n",
    "    # nueva instancia del modelos con semilla\n",
    "    seed = s + (7+j)\n",
    "    print(f\"Entrenando modelo con semilla: {seed}, {j+1} de {s_total}\")\n",
    "    # model = LGBMClassifier(**params, random_state=seed)\n",
    "    # # entreno\n",
    "    # model.fit(X=X_train_imp, y=y_train_binaria)\n",
    "\n",
    "    # seteo semilla\n",
    "    params.update({'seed': seed})\n",
    "    # training set\n",
    "    train_data = lgbm.Dataset(X_train_imp,\n",
    "                              label=y_train_binaria,\n",
    "                              weight=w_train)\n",
    "    model = lgbm.train(params,\n",
    "                       train_data,\n",
    "                       num_boost_round=1509) # best iteration de opt\n",
    "    \n",
    "    # predigo proba\n",
    "    # y_pred_proba = model.predict_proba(X_kaggle_imp)\n",
    "    y_pred_proba = model.predict(X_kaggle_imp, raw_score=False)\n",
    "    # proba baja+2\n",
    "    # proba_baja2 = y_pred_proba[:,2]\n",
    "    # df_sem_proba[f'proba_s{seed}'] = proba_baja\n",
    "    df_sem_proba[f'proba_s{seed}'] = y_pred_proba\n",
    "    j += 1\n",
    "\n",
    "# Promediando proba de cada semilla\n",
    "proba_s_columns = df_sem_proba.filter(regex='^proba_s')\n",
    "proba_s_mean = proba_s_columns.mean(axis=1)\n",
    "\n",
    "df_sem_proba['proba_sem_mean'] = proba_s_mean\n",
    "\n",
    "# Umbral\n",
    "thr_opt_sem = 0.485 # Segun Denicolay, el óptimo ronda los 11 mil estímulos\n",
    "\n",
    "# Prediccion\n",
    "df_sem_proba['pred'] = np.where(df_sem_proba.proba_sem_mean >= thr_opt_sem, 1, 0)\n",
    "\n",
    "df_sem_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'numero_de_cliente': numero_de_cliente.values,\n",
    "    'Predicted': df_sem_proba['pred'].values\n",
    "})\n",
    "\n",
    "# Imprimir value counts de las predicciones\n",
    "value_counts = submission['Predicted'].value_counts()\n",
    "total_count = len(submission)\n",
    "print(\"\\nValue Counts:\")\n",
    "print(value_counts)\n",
    "print(\"\\nFrecuencia Relativa:\")\n",
    "print((value_counts / total_count) * 100)\n",
    "\n",
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = \"%dT-%m-%Y%H-%M-%S\"\n",
    "t_now = datetime.datetime.now().strftime(ft)\n",
    "\n",
    "pred_name = f\"pred_sem_03_eug_sem{s_total}__th0.485\"+t_now+\".csv\"\n",
    "\n",
    "proba_file = pred_path + \"probas/\" + pred_name\n",
    "pred_file = pred_path + pred_name\n",
    "\n",
    "# Guardamos las probas\n",
    "df_sem_proba.to_csv(proba_file, index=False)\n",
    "print(f\"Probas guardadas en {proba_file}\")\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "submission.to_csv(pred_file, index=False)\n",
    "print(f\"Predicciones guardadas en {pred_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_eyf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
