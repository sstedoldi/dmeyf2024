{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNoCqM1I5-le"
   },
   "source": [
    "# Back-testing\n",
    "\n",
    "> Modelo optimizado, evaluado con semillas para explorar el umbral óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santtedo/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Librerias\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#######\n",
    "# rutas\n",
    "# datasets\n",
    "from config import dataset_file_fe6_6xpqt\n",
    "from config import db_path\n",
    "# modelos\n",
    "from config import modelos_path\n",
    "# predicciones\n",
    "from config import pred_path\n",
    "\n",
    "##########\n",
    "# pipeline\n",
    "from processing import ModelPipeline, plot_comparisons_on_kaggle_split\n",
    "from processing import analyze_study\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "# Ignorar advertencias de tipo UserWarning\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='pandas')\n",
    "warnings.filterwarnings('ignore', category=Warning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train_all = [201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
    "                 201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
    "                 202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_3_meses = [202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_6_meses = [202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_9_meses = [202010, 202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_anio = [202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train = [202107]\n",
    "mes_test = 202109\n",
    "\n",
    "threshold = 0.025\n",
    "\n",
    "semillas = [437809, 327347, 392879, 455783, 217163]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IbyPo4Dk4Mdh"
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(dataset_file_fe6_6xpqt)\n",
    "\n",
    "# running local\n",
    "# data = pd.read_parquet(\"datos/datasets_competencia_03_fe6x_opt_under.parquet\")\n",
    "\n",
    "# Mapear etiquetas de clase a números\n",
    "label_mapping = {'CONTINUA': 0, 'BAJA+1': 1, 'BAJA+2': 2}\n",
    "\n",
    "data['clase_ternaria'] = data['clase_ternaria'].map(label_mapping)\n",
    "\n",
    "# Simulación para Kaggle\n",
    "mes_bt_ult_anio = [202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105]\n",
    "\n",
    "X_train = data[data['foto_mes'].isin(mes_bt_ult_anio)]\n",
    "y_train = X_train['clase_ternaria']\n",
    "X_train = X_train.drop(columns=['clase_ternaria'])\n",
    "\n",
    "mes_futuro = 202107 # usado como test\n",
    "X_test = data[data['foto_mes'] == mes_futuro]\n",
    "y_test = X_test['clase_ternaria']\n",
    "X_test = X_test.drop(columns=['clase_ternaria'])\n",
    "\n",
    "del data\n",
    "\n",
    "# ESTO PARECE ROMPER LOS MODELOS\n",
    "# data_futuro = pd.read_parquet(dataset_202107)\n",
    "\n",
    "# running local\n",
    "# data_futuro = pd.read_parquet(\"datos/datasets_competencia_03_202107.parquet\")\n",
    "\n",
    "# mes_futuro = 202107 # usado como test\n",
    "# X_test = data_futuro[data_futuro['foto_mes'] == mes_futuro]\n",
    "# y_test = X_test['clase_ternaria']\n",
    "# X_test = X_test.drop(columns=['clase_ternaria'])\n",
    "\n",
    "# del data_futuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesando data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with all NaN values: ['payroll_slope_1_foto_mes', 'cuenta_corriente_slope_1_foto_mes', 'visa_consumo_slope_1_foto_mes', 'comisiones_mantenimiento_slope_1_foto_mes', 'comisiones_otras_slope_1_foto_mes']\n"
     ]
    }
   ],
   "source": [
    "# Imputacion de Xs\n",
    "cols_with_all_nan = X_train.columns[X_train.isna().all()].tolist()\n",
    "print(\"Columns with all NaN values:\", cols_with_all_nan)\n",
    "X_train = X_train.drop(columns=cols_with_all_nan)\n",
    "X_test = X_test.drop(columns=cols_with_all_nan)\n",
    "\n",
    "# Imputación de nulls\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_train_imp = pd.DataFrame(imp_median.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imp = pd.DataFrame(imp_median.transform(X_test), columns=X_train.columns)\n",
    "\n",
    "del X_train\n",
    "del X_test\n",
    "\n",
    "# Codificar variables categóricas\n",
    "categorical_features = [col for col in X_train_imp.columns if X_train_imp[col].dtype == 'object']\n",
    "\n",
    "# Convertir variables categóricas a 'category' dtype para LightGBM\n",
    "for col in categorical_features:\n",
    "    X_train_imp[col] = X_train_imp[col].astype('category')\n",
    "    X_test_imp[col] = X_test_imp[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos candidatos\n",
    "\n",
    "Luego de una comparación de modelos candidatos en comp03_pipeline_comp\n",
    "\n",
    "Se decide optar como **modelo optimizado** el:\n",
    "\n",
    "> **lgbm prepro6 fe6 y 12 opt (local opt 10 % de CONTINUA)**\n",
    "\n",
    "Además, se trabaja con un modelo semillero, en comp03_back-testing_sem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del punto de corte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganancia(y, y_hat, thr, \n",
    "             ganancia_acierto = ganancia_acierto, \n",
    "             costo_estimulo = costo_estimulo,\n",
    "             target = 2, prop=1):\n",
    "\n",
    "    # Calcular la ganancia para cada fila\n",
    "    gains = np.where(y_hat >= thr, np.where(y == target, ganancia_acierto, -costo_estimulo), 0)\n",
    "\n",
    "    # Sumar las ganancias\n",
    "    estimated_gain = gains.sum()/prop\n",
    "\n",
    "    return estimated_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento con óptimos parámetros\n",
    "\n",
    "**Modelo regular**\n",
    "\n",
    "Con las distintas semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(range(217163, 455783, 7*7*7*7))) # 100 semillas\n",
    "# len(list(range(217163, 455783, 7*7*7*7*2))) # 50 semillas\n",
    "# len(list(range(217163, 455783, 7*7*7*7*4))) # 25 semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running back-testing for LGBMClassifier\n",
      "{'n_estimators': 532, 'num_leaves': 74, 'learning_rate': 0.02597037622291732, 'min_data_in_leaf': 160, 'feature_fraction': 0.5306395912844186, 'n_jobs': -1}\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.895606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86140\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 659\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 217163, ganancia max: 163492000.0, thr: 0.014324324324324324, estimulos: 12604\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.818549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86210\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 659\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 229168, ganancia max: 164038000.0, thr: 0.014844844844844845, estimulos: 12406\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.178187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86121\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 659\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 241173, ganancia max: 163464000.0, thr: 0.015565565565565565, estimulos: 11768\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.926232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86096\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 659\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 253178, ganancia max: 162715000.0, thr: 0.015025025025025025, estimulos: 12155\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.776475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86185\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 658\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 265183, ganancia max: 163744000.0, thr: 0.012982982982982982, estimulos: 13608\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.046603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86203\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 658\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 277188, ganancia max: 163345000.0, thr: 0.014404404404404405, estimulos: 12625\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.061141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86254\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 659\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 289193, ganancia max: 163464000.0, thr: 0.018448448448448448, estimulos: 10248\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.825397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86033\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 658\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 301198, ganancia max: 162988000.0, thr: 0.012382382382382382, estimulos: 14076\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.870589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86263\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 659\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 313203, ganancia max: 165046000.0, thr: 0.012322322322322322, estimulos: 14022\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.112409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86122\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 659\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 325208, ganancia max: 163233000.0, thr: 0.014584584584584583, estimulos: 12481\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.530133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 86128\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 660\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 337213, ganancia max: 161553000.0, thr: 0.013403403403403402, estimulos: 13401\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.855741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86093\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 659\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 349218, ganancia max: 162316000.0, thr: 0.012982982982982982, estimulos: 13612\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 5.921241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 86220\n",
      "[LightGBM] [Info] Number of data points in the train set: 1614498, number of used features: 659\n",
      "[LightGBM] [Info] Start training from score -0.009347\n",
      "[LightGBM] [Info] Start training from score -5.394395\n",
      "[LightGBM] [Info] Start training from score -5.347249\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopt_params, random_state\u001b[38;5;241m=\u001b[39ms)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# entreno\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_imp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# predigo proba\u001b[39;00m\n\u001b[1;32m     46\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_imp)\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py:1284\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1282\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1284\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/lightgbm/sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/lightgbm/engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    296\u001b[0m     cb(\n\u001b[1;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m         )\n\u001b[1;32m    305\u001b[0m     )\n\u001b[0;32m--> 307\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.12/site-packages/lightgbm/basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4135\u001b[0m _safe_call(\n\u001b[0;32m-> 4136\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4140\u001b[0m )\n\u001b[1;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Tomando al mejor modelo optimizado\n",
    "\n",
    "# prepro = 6 # data quality + data drifting\n",
    "# fe = 6 # feature engineering conceptual 6 meses\n",
    "# training = 3 # un mes de optimización\n",
    "\n",
    "storage_name = \"sqlite:///\" + db_path + \"optimization_tree.db\"\n",
    "\n",
    "# carga local\n",
    "# storage_name = \"sqlite:///optimizacion/optimization_tree.db\"\n",
    "study_name = f\"exp_lgbm_comp03_local_v00\"\n",
    "\n",
    "study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "\n",
    "# Mejores parámetros\n",
    "opt_params = study.best_trial.params\n",
    "opt_params.update({'n_jobs': -1})\n",
    "\n",
    "print(\"Running back-testing for LGBMClassifier\")\n",
    "print(opt_params)\n",
    "\n",
    "# para registrar las probabilidades\n",
    "df_s_proba = pd.DataFrame({\n",
    "                            'client': y_test.index,\n",
    "                            'baja': y_test.values,\n",
    "                        })\n",
    "\n",
    "label_antimapping = {0:'CONTINUA', 1:'BAJA+1', 2:'BAJA+2'}\n",
    "df_s_proba['clase_ternaria'] = df_s_proba['baja'].map(label_antimapping)\n",
    "\n",
    "seeds = []\n",
    "max_ganancia = []\n",
    "max_ganancia_thr = []\n",
    "max_ganancia_esti = []\n",
    "\n",
    "s_r = range(217163, 455783, 7*7*7*7*5) # 20 semillas\n",
    "total_s = len(list(s_r)) \n",
    "for s in s_r: \n",
    "    # nueva instancia del modelos con semilla\n",
    "    model = LGBMClassifier(**opt_params, random_state=s)\n",
    "    # entreno\n",
    "    model.fit(X_train_imp, y_train)\n",
    "    # predigo proba\n",
    "    y_pred_proba = model.predict_proba(X_test_imp)\n",
    "    # proba baja+2\n",
    "    proba_baja2 = y_pred_proba[:,2]\n",
    "    df_s_proba[f'proba_{s}'] = proba_baja2\n",
    "\n",
    "    # dataframe con el test\n",
    "    test_results = pd.DataFrame({\n",
    "                            'client': y_test.index,\n",
    "                            'baja': y_test.values,\n",
    "                            'proba_baja2' : y_pred_proba[:,2]\n",
    "                        })\n",
    "    test_results['clase_ternaria'] = test_results['baja'].map(label_antimapping)\n",
    "\n",
    "    # ganancias según threshold\n",
    "    thrs = []\n",
    "    ganancias = []\n",
    "    estimulos = []\n",
    "    for thr in np.linspace(0.01, 0.03, 1000):\n",
    "        gain = ganancia(test_results.baja, test_results.proba_baja2, thr)\n",
    "        esti = np.where(test_results.proba_baja2 >= thr, 1, 0).sum()\n",
    "        thrs.append(thr)\n",
    "        ganancias.append(gain)\n",
    "        estimulos.append(esti)\n",
    "        \n",
    "    df_ganancias = pd.DataFrame({\n",
    "                                'threshold': thrs,\n",
    "                                'ganancias': ganancias,\n",
    "                                'estimulos': estimulos\n",
    "                            })\n",
    "\n",
    "    # maxima ganancia\n",
    "    max_gain_idx = df_ganancias['ganancias'].idxmax()\n",
    "    max_gain = df_ganancias['ganancias'][max_gain_idx]\n",
    "    max_gain_thr = df_ganancias['threshold'][max_gain_idx]\n",
    "    max_estimulos = df_ganancias['estimulos'][max_gain_idx]\n",
    "    \n",
    "    # registro condiciones de maxima\n",
    "    seeds.append(s)\n",
    "    max_ganancia.append(max_gain)\n",
    "    max_ganancia_thr.append(max_gain_thr)\n",
    "    max_ganancia_esti.append(max_estimulos)\n",
    "\n",
    "    print(f\"\\ns: {s}, ganancia max: {max_gain}, thr: {max_gain_thr}, estimulos: {max_estimulos}\\n\\n\")\n",
    "\n",
    "df_ganancias_semillas = pd.DataFrame({\n",
    "                            'semillas': seeds,\n",
    "                            'max_ganancias': max_ganancia,\n",
    "                            'threshold': max_ganancia_thr,\n",
    "                            'estimulos': max_ganancia_esti,\n",
    "                        })\n",
    "\n",
    "df_ganancias_semillas.to_csv(db_path+'df_ganancias_semillas.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis del threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ganancias_semillas = pd.DataFrame({\n",
    "                            'semillas': seeds,\n",
    "                            'max_ganancias': max_ganancia,\n",
    "                            'threshold': max_ganancia_thr,\n",
    "                            'estimulos': max_ganancia_esti,\n",
    "                        })\n",
    "\n",
    "df_ganancias_semillas.to_csv(db_path+'df_ganancias_semillas.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ganancias_semillas = pd.read_csv('df_ganancias_semillas.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semillas</th>\n",
       "      <th>max_ganancias</th>\n",
       "      <th>threshold</th>\n",
       "      <th>estimulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217163</td>\n",
       "      <td>163492000.0</td>\n",
       "      <td>0.014324</td>\n",
       "      <td>12604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229168</td>\n",
       "      <td>164038000.0</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>12406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241173</td>\n",
       "      <td>163464000.0</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>11768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253178</td>\n",
       "      <td>162715000.0</td>\n",
       "      <td>0.015025</td>\n",
       "      <td>12155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265183</td>\n",
       "      <td>163744000.0</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>13608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   semillas  max_ganancias  threshold  estimulos\n",
       "0    217163    163492000.0   0.014324      12604\n",
       "1    229168    164038000.0   0.014845      12406\n",
       "2    241173    163464000.0   0.015566      11768\n",
       "3    253178    162715000.0   0.015025      12155\n",
       "4    265183    163744000.0   0.012983      13608"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ganancias_semillas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semillas</th>\n",
       "      <th>max_ganancias</th>\n",
       "      <th>threshold</th>\n",
       "      <th>estimulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>283190.500000</td>\n",
       "      <td>1.632832e+08</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>12750.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43284.643062</td>\n",
       "      <td>8.709399e+05</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>1090.673562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>217163.000000</td>\n",
       "      <td>1.615530e+08</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>10248.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250176.750000</td>\n",
       "      <td>1.629198e+08</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>12343.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>283190.500000</td>\n",
       "      <td>1.634045e+08</td>\n",
       "      <td>0.014364</td>\n",
       "      <td>12614.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>316204.250000</td>\n",
       "      <td>1.635550e+08</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>13609.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>349218.000000</td>\n",
       "      <td>1.650460e+08</td>\n",
       "      <td>0.018448</td>\n",
       "      <td>14076.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            semillas  max_ganancias  threshold     estimulos\n",
       "count      12.000000   1.200000e+01  12.000000     12.000000\n",
       "mean   283190.500000   1.632832e+08   0.014273  12750.500000\n",
       "std     43284.643062   8.709399e+05   0.001694   1090.673562\n",
       "min    217163.000000   1.615530e+08   0.012322  10248.000000\n",
       "25%    250176.750000   1.629198e+08   0.012983  12343.250000\n",
       "50%    283190.500000   1.634045e+08   0.014364  12614.500000\n",
       "75%    316204.250000   1.635550e+08   0.014890  13609.000000\n",
       "max    349218.000000   1.650460e+08   0.018448  14076.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ganancias_semillas.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media del threshold para ganancias máximas en backtesting está en 0.01427 de proba y 0.01436 de mediana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
