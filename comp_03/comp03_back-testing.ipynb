{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNoCqM1I5-le"
   },
   "source": [
    "# Back-testing\n",
    "\n",
    "Incluye:\n",
    "\n",
    "- Uso de datos undersampling para train, calculando threshold opt red\n",
    "- Uso de datos totales para train, para calcular threshold opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#######\n",
    "# rutas\n",
    "# datasets\n",
    "from config import dataset_file_fe6_6xpqt,\\\n",
    "                   dataset_file_fe6_6xpqt_opt_under,\\\n",
    "                   dataset_202107\n",
    "# optimizacion\n",
    "from config import db_path\n",
    "# modelos\n",
    "from config import modelos_path\n",
    "# predicciones\n",
    "from config import pred_path\n",
    "\n",
    "##########\n",
    "# pipeline\n",
    "from processing import ModelPipeline, plot_comparisons_on_kaggle_split\n",
    "from processing import analyze_study\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "# Ignorar advertencias de tipo UserWarning\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='pandas')\n",
    "warnings.filterwarnings('ignore', category=Warning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train_all = [201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
    "                 201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
    "                 202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_3_meses = [202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_6_meses = [202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_9_meses = [202010, 202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_anio = [202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train = [202107]\n",
    "mes_test = 202109\n",
    "\n",
    "threshold = 0.025\n",
    "\n",
    "semillas = [437809, 327347, 392879, 455783, 217163]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbyPo4Dk4Mdh"
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(dataset_file_fe6_6xpqt)\n",
    "\n",
    "# running local\n",
    "# data = pd.read_parquet(\"datos/datasets_competencia_03_fe6x_opt_under.parquet\")\n",
    "\n",
    "# Mapear etiquetas de clase a números\n",
    "label_mapping = {'CONTINUA': 0, 'BAJA+1': 1, 'BAJA+2': 2}\n",
    "\n",
    "data['clase_ternaria'] = data['clase_ternaria'].map(label_mapping)\n",
    "\n",
    "# Simulación para Kaggle\n",
    "mes_bt_ult_anio = [202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105]\n",
    "\n",
    "X_train = data[data['foto_mes'].isin(mes_bt_ult_anio)]\n",
    "y_train = X_train['clase_ternaria']\n",
    "X_train = X_train.drop(columns=['clase_ternaria'])\n",
    "\n",
    "del data\n",
    "\n",
    "data_futuro = pd.read_parquet(dataset_202107)\n",
    "\n",
    "# running local\n",
    "# data_futuro = pd.read_parquet(\"datos/datasets_competencia_03_202107.parquet\")\n",
    "\n",
    "mes_futuro = 202107 # usado como test\n",
    "X_test = data_futuro[data_futuro['foto_mes'] == mes_futuro]\n",
    "y_test = X_test['clase_ternaria']\n",
    "X_test = X_test.drop(columns=['clase_ternaria'])\n",
    "\n",
    "del data_futuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesando data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with all NaN values: ['payroll_slope_1_foto_mes', 'cuenta_corriente_slope_1_foto_mes', 'visa_consumo_slope_1_foto_mes', 'comisiones_mantenimiento_slope_1_foto_mes', 'comisiones_otras_slope_1_foto_mes']\n"
     ]
    }
   ],
   "source": [
    "# Imputacion de Xs\n",
    "cols_with_all_nan = X_train.columns[X_train.isna().all()].tolist()\n",
    "print(\"Columns with all NaN values:\", cols_with_all_nan)\n",
    "X_train = X_train.drop(columns=cols_with_all_nan)\n",
    "X_test = X_test.drop(columns=cols_with_all_nan)\n",
    "\n",
    "# Imputación de nulls\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_train_imp = pd.DataFrame(imp_median.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imp = pd.DataFrame(imp_median.transform(X_test), columns=X_train.columns)\n",
    "\n",
    "del X_train\n",
    "del X_test\n",
    "\n",
    "# Codificar variables categóricas\n",
    "categorical_features = [col for col in X_train_imp.columns if X_train_imp[col].dtype == 'object']\n",
    "\n",
    "# Convertir variables categóricas a 'category' dtype para LightGBM\n",
    "for col in categorical_features:\n",
    "    X_train_imp[col] = X_train_imp[col].astype('category')\n",
    "    X_test_imp[col] = X_test_imp[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos candidatos\n",
    "\n",
    "Luego de una comparación de modelos candidatos en comp02_pipeline_comp\n",
    "\n",
    "Se decide optar como **modelo regular** el:\n",
    "\n",
    "> **xgb prepro6 fe6 y 3 opt (local opt parcial)**\n",
    "\n",
    "Mientras que, para calcular una predicción con semillerío:\n",
    "\n",
    "Modelo **semillero de Denicolay** (modificado)\n",
    "\n",
    "semillerio_params = {'n_estimators': 23,\n",
    "                  'num_leaves': 32,\n",
    "                  'learning_rate': 0.34,\n",
    "                  'min_data_in_leaf': 711,\n",
    "                  'feature_fraction': 2*0.2, # x2 para tratar de compenzar la falta de variables\n",
    "                  'extra_trees': False,\n",
    "                  'random_state': semillas[s],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del punto de corte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganancia(y, y_hat, thr, \n",
    "             ganancia_acierto = ganancia_acierto, \n",
    "             costo_estimulo = costo_estimulo,\n",
    "             target = 2, prop=1):\n",
    "\n",
    "    # Calcular la ganancia para cada fila\n",
    "    gains = np.where(y_hat >= thr, np.where(y == target, ganancia_acierto, -costo_estimulo), 0)\n",
    "\n",
    "    # Sumar las ganancias\n",
    "    estimated_gain = gains.sum()/prop\n",
    "\n",
    "    return estimated_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento con óptimos parámetros\n",
    "\n",
    "**Modelo regular**\n",
    "\n",
    "Con las distintas semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(range(217163, 455783, 7*7*7*7))) # 100 semillas\n",
    "# len(list(range(217163, 455783, 7*7*7*7*2))) # 50 semillas\n",
    "# len(list(range(217163, 455783, 7*7*7*7*4))) # 25 semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running back-testing for LGBMClassifier\n",
      "{'n_estimators': 532, 'num_leaves': 74, 'learning_rate': 0.02597037622291732, 'min_data_in_leaf': 160, 'feature_fraction': 0.5306395912844186, 'n_jobs': -5}\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.291446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 85183\n",
      "[LightGBM] [Info] Number of data points in the train set: 175211, number of used features: 649\n",
      "[LightGBM] [Info] Start training from score -0.089624\n",
      "[LightGBM] [Info] Start training from score -3.173606\n",
      "[LightGBM] [Info] Start training from score -3.126460\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "\n",
      "s: 217163, ganancia max: 0.0, thr: 0.5623832383238324, estimulos: 0\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=160, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=160\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306395912844186, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306395912844186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.323846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 85183\n",
      "[LightGBM] [Info] Number of data points in the train set: 175211, number of used features: 649\n",
      "[LightGBM] [Info] Start training from score -0.089624\n",
      "[LightGBM] [Info] Start training from score -3.173606\n",
      "[LightGBM] [Info] Start training from score -3.126460\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopt_params, random_state\u001b[38;5;241m=\u001b[39ms)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# entreno\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_imp, y_train)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# predigo proba\u001b[39;00m\n\u001b[0;32m     46\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_imp)\n",
      "File \u001b[1;32mc:\\Users\\santt\\.conda\\envs\\dm_eyf\\Lib\\site-packages\\lightgbm\\sklearn.py:1284\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1282\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[1;32m-> 1284\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1285\u001b[0m     X,\n\u001b[0;32m   1286\u001b[0m     _y,\n\u001b[0;32m   1287\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1288\u001b[0m     init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[0;32m   1289\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[0;32m   1290\u001b[0m     eval_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[0;32m   1291\u001b[0m     eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[0;32m   1292\u001b[0m     eval_class_weight\u001b[38;5;241m=\u001b[39meval_class_weight,\n\u001b[0;32m   1293\u001b[0m     eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score,\n\u001b[0;32m   1294\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[0;32m   1295\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[0;32m   1296\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[0;32m   1297\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1298\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[0;32m   1299\u001b[0m )\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\santt\\.conda\\envs\\dm_eyf\\Lib\\site-packages\\lightgbm\\sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m    956\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    957\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[0;32m    958\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[0;32m    959\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[0;32m    960\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[0;32m    961\u001b[0m     feval\u001b[38;5;241m=\u001b[39meval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[0;32m    963\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    964\u001b[0m )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[1;32mc:\\Users\\santt\\.conda\\envs\\dm_eyf\\Lib\\site-packages\\lightgbm\\engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    296\u001b[0m     cb(\n\u001b[0;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    305\u001b[0m     )\n\u001b[1;32m--> 307\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)\n\u001b[0;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\santt\\.conda\\envs\\dm_eyf\\Lib\\site-packages\\lightgbm\\basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4135\u001b[0m _safe_call(\n\u001b[1;32m-> 4136\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterUpdateOneIter(\n\u001b[0;32m   4137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[0;32m   4138\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(is_finished),\n\u001b[0;32m   4139\u001b[0m     )\n\u001b[0;32m   4140\u001b[0m )\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Tomando al mejor modelo optimizado\n",
    "\n",
    "# prepro = 6 # data quality + data drifting\n",
    "# fe = 6 # feature engineering conceptual 6 meses\n",
    "# training = 3 # un mes de optimización\n",
    "\n",
    "# storage_name = \"sqlite:///\" + db_path + \"optimization_tree.db\"\n",
    "\n",
    "# carga local\n",
    "storage_name = \"sqlite:///optimizacion/optimization_tree.db\"\n",
    "study_name = f\"exp_lgbm_comp03_local_v00\"\n",
    "\n",
    "study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "\n",
    "# Mejores parámetros\n",
    "opt_params = study.best_trial.params\n",
    "opt_params.update({'n_jobs': -1})\n",
    "\n",
    "print(\"Running back-testing for LGBMClassifier\")\n",
    "print(opt_params)\n",
    "\n",
    "# para registrar las probabilidades\n",
    "df_s_proba = pd.DataFrame({\n",
    "                            'client': y_test.index,\n",
    "                            'baja': y_test.values,\n",
    "                        })\n",
    "\n",
    "label_antimapping = {0:'CONTINUA', 1:'BAJA+1', 2:'BAJA+2'}\n",
    "df_s_proba['clase_ternaria'] = df_s_proba['baja'].map(label_antimapping)\n",
    "\n",
    "seeds = []\n",
    "max_ganancia = []\n",
    "max_ganancia_thr = []\n",
    "max_ganancia_esti = []\n",
    "\n",
    "s_r = range(217163, 455783, 7*7*7*7*5) # 20 semillas\n",
    "total_s = len(list(s_r)) \n",
    "for s in s_r: \n",
    "    # nueva instancia del modelos con semilla\n",
    "    model = LGBMClassifier(**opt_params, random_state=s)\n",
    "    # entreno\n",
    "    model.fit(X_train_imp, y_train)\n",
    "    # predigo proba\n",
    "    y_pred_proba = model.predict_proba(X_test_imp)\n",
    "    # proba baja+2\n",
    "    proba_baja2 = y_pred_proba[:,2]\n",
    "    df_s_proba[f'proba_{s}'] = proba_baja2\n",
    "\n",
    "    # dataframe con el test\n",
    "    test_results = pd.DataFrame({\n",
    "                            'client': y_test.index,\n",
    "                            'baja': y_test.values,\n",
    "                            'proba_baja2' : y_pred_proba[:,2]\n",
    "                        })\n",
    "    test_results['clase_ternaria'] = test_results['baja'].map(label_antimapping)\n",
    "\n",
    "    # ganancias según threshold\n",
    "    thrs = []\n",
    "    ganancias = []\n",
    "    estimulos = []\n",
    "    for thr in np.linspace(0.01, 0.03, 1000):\n",
    "        gain = ganancia(test_results.baja, test_results.proba_baja2, thr)\n",
    "        esti = np.where(test_results.proba_baja2 >= thr, 1, 0).sum()\n",
    "        thrs.append(thr)\n",
    "        ganancias.append(gain)\n",
    "        estimulos.append(esti)\n",
    "        \n",
    "    df_ganancias = pd.DataFrame({\n",
    "                                'threshold': thrs,\n",
    "                                'ganancias': ganancias,\n",
    "                                'estimulos': estimulos\n",
    "                            })\n",
    "\n",
    "    # maxima ganancia\n",
    "    max_gain_idx = df_ganancias['ganancias'].idxmax()\n",
    "    max_gain = df_ganancias['ganancias'][max_gain_idx]\n",
    "    max_gain_thr = df_ganancias['threshold'][max_gain_idx]\n",
    "    max_estimulos = df_ganancias['estimulos'][max_gain_idx]\n",
    "    \n",
    "    # registro condiciones de maxima\n",
    "    seeds.append(s)\n",
    "    max_ganancia.append(max_gain)\n",
    "    max_ganancia_thr.append(max_gain_thr)\n",
    "    max_ganancia_esti.append(max_estimulos)\n",
    "\n",
    "    print(f\"\\ns: {s}, ganancia max: {max_gain}, thr: {max_gain_thr}, estimulos: {max_estimulos}\\n\\n\")\n",
    "\n",
    "df_ganancias_semillas = pd.DataFrame({\n",
    "                            'semillas': seeds,\n",
    "                            'max_ganancias': max_ganancia,\n",
    "                            'threshold': max_ganancia_thr,\n",
    "                            'estimulos': max_ganancia_esti,\n",
    "                        })\n",
    "\n",
    "df_ganancias_semillas.to_csv(db_path+'df_ganancias_semillas.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis del threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ganancias_semillas = pd.read_csv('df_ganancias_semillas.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semillas</th>\n",
       "      <th>max_ganancias</th>\n",
       "      <th>threshold</th>\n",
       "      <th>estimulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217163</td>\n",
       "      <td>95900000</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>13420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217212</td>\n",
       "      <td>95473000</td>\n",
       "      <td>0.020505</td>\n",
       "      <td>9401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217261</td>\n",
       "      <td>96747000</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>10899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217310</td>\n",
       "      <td>96971000</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>12947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217359</td>\n",
       "      <td>96369000</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>12633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   semillas  max_ganancias  threshold  estimulos\n",
       "0    217163       95900000   0.013636      13420\n",
       "1    217212       95473000   0.020505       9401\n",
       "2    217261       96747000   0.017273      10899\n",
       "3    217310       96971000   0.014444      12947\n",
       "4    217359       96369000   0.014848      12633"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ganancias_semillas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semillas</th>\n",
       "      <th>max_ganancias</th>\n",
       "      <th>threshold</th>\n",
       "      <th>estimulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>218461.500000</td>\n",
       "      <td>9.704541e+07</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>12174.148148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>770.874503</td>\n",
       "      <td>7.293960e+05</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>1361.594451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>217163.000000</td>\n",
       "      <td>9.515800e+07</td>\n",
       "      <td>0.012828</td>\n",
       "      <td>9048.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>217812.250000</td>\n",
       "      <td>9.663325e+07</td>\n",
       "      <td>0.014040</td>\n",
       "      <td>11299.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>218461.500000</td>\n",
       "      <td>9.707950e+07</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>12580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>219110.750000</td>\n",
       "      <td>9.756075e+07</td>\n",
       "      <td>0.016768</td>\n",
       "      <td>13111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>219760.000000</td>\n",
       "      <td>9.919000e+07</td>\n",
       "      <td>0.021313</td>\n",
       "      <td>14440.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            semillas  max_ganancias  threshold     estimulos\n",
       "count      54.000000   5.400000e+01  54.000000     54.000000\n",
       "mean   218461.500000   9.704541e+07   0.015627  12174.148148\n",
       "std       770.874503   7.293960e+05   0.002141   1361.594451\n",
       "min    217163.000000   9.515800e+07   0.012828   9048.000000\n",
       "25%    217812.250000   9.663325e+07   0.014040  11299.750000\n",
       "50%    218461.500000   9.707950e+07   0.014848  12580.000000\n",
       "75%    219110.750000   9.756075e+07   0.016768  13111.000000\n",
       "max    219760.000000   9.919000e+07   0.021313  14440.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ganancias_semillas.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media del threshold para ganancias máximas en backtesting está en 0.0156 de proba y 0.0148 de mediana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dm_eyf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
