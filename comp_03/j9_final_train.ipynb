{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando notebook de Eugenio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgbm\n",
    "\n",
    "#######\n",
    "# rutas\n",
    "# datasets\n",
    "from config import dataset_file_fe6_6xxpqt, dataset_file_fe6_6xxpqt_under # con lag1&2 + delta1&2\n",
    "      \n",
    "# optimizacion\n",
    "from config import db_path\n",
    "# modelos\n",
    "from config import modelos_path\n",
    "# predicciones\n",
    "from config import pred_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "semillas = [437809, 327347, 392879, 455783, 217163]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(dataset_file_fe6_6xxpqt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampleo con bajas unificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unificación de bajas\n",
    "data['clase_binaria'] = 0\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria'] == 'BAJA+2', 1, 0)\n",
    "\n",
    "# quitando meses sin clase \n",
    "meses_excluidos = [202108, 202109] # meses con clase ternaria incompleta\n",
    "data = data[~data['foto_mes'].isin(meses_excluidos)]\n",
    "data['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsampled = []\n",
    "\n",
    "for mes, group in data.groupby(\"foto_mes\"):\n",
    "\n",
    "    X = group.drop(columns=\"clase_binaria\")\n",
    "    y = group[\"clase_binaria\"]\n",
    "    \n",
    "    # Calculo la proporcion de bajas\n",
    "    minority_proportion = y.value_counts(normalize=True).get(1, 0)\n",
    "    \n",
    "    # voy a incrementar esa proporcion por 10\n",
    "\n",
    "    estrategia={0: int(len(y[y == 0]) * 0.02), \n",
    "                1: len(y[y == 1])}\n",
    "\n",
    "    print(f\"Se retienen {estrategia[0]} de la clase mayoritaria y {estrategia[1]} de la minoritaria\")\n",
    "    \n",
    "    # new_proportion = minority_proportion * 10\n",
    "\n",
    "    rus = RandomUnderSampler(sampling_strategy=estrategia, random_state=semillas[0])\n",
    "    X_res, y_res = rus.fit_resample(X, y)\n",
    "\n",
    "    # Rearmar\n",
    "    group_resampled = pd.concat([X_res, y_res], axis=1)\n",
    "    group_resampled[\"foto_mes\"] = mes\n",
    "\n",
    "    df_subsampled.append(group_resampled)\n",
    "\n",
    "# Mergear\n",
    "data = pd.concat(df_subsampled, ignore_index=True)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo por las dudas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet(dataset_file_fe6_6xxpqt_under, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
       "       201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
       "       202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
       "       202101, 202102, 202103, 202104, 202105, 202106, 202107])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para recordar los periodos en los que entrenamos el modelo final:\n",
    "data['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112198, 764)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos pesos a las clases\n",
    "\n",
    "data['clase_peso'] = 1.0\n",
    "\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_binaria'] = 0\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria'] == 'CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria'], axis=1)\n",
    "\n",
    "# Imputacion de Xs\n",
    "cols_with_all_nan = X_train.columns[X_train.isna().all()].tolist()\n",
    "print(\"Columns with all NaN values:\", cols_with_all_nan)\n",
    "X_train = X_train.drop(columns=cols_with_all_nan)\n",
    "\n",
    "# Imputación de nulls\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_train_imp = pd.DataFrame(imp_median.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Codificar variables categóricas\n",
    "categorical_features = [col for col in X_train_imp.columns if X_train_imp[col].dtype == 'object']\n",
    "\n",
    "# Convertir variables categóricas a 'category' dtype para LightGBM\n",
    "for col in categorical_features:\n",
    "    X_train_imp[col] = X_train_imp[col].astype('category')\n",
    "\n",
    "y_train_binaria = data['clase_binaria'] # Junta a los 2 baja\n",
    "w_train = data['clase_peso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejores parametros\n",
    "\n",
    "Eugenio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 470,\n",
    "            'learning_rate': 0.006845251039139201,\n",
    "            'min_data_in_leaf': 305,\n",
    "            'feature_fraction': 0.4104147707505324,\n",
    "            'bagging_fraction': 0.1016227845120685}\n",
    "\n",
    "params.update({'n_jobs': -1,\n",
    "                'objective': 'binary',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'first_metric_only': True,\n",
    "                'boost_from_average': True,\n",
    "                'feature_pre_filter': False,\n",
    "                'max_bin': 31,\n",
    "               })\n",
    "\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos a predecir para Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vuelvo a leer sin undersamplear\n",
    "data_ = pd.read_parquet(dataset_file_fe6_6xxpqt)\n",
    "\n",
    "mes_test = 202109\n",
    "\n",
    "X_kaggle = data_[data_['foto_mes'] == mes_test]\n",
    "X_kaggle = X_kaggle.drop(columns=['clase_ternaria']) # nulls\n",
    "\n",
    "del data_\n",
    "\n",
    "# prepro en X:kaggle\n",
    "X_kaggle = X_kaggle.drop(columns=cols_with_all_nan)\n",
    "X_kaggle_imp = pd.DataFrame(imp_median.transform(X_kaggle), columns=X_train.columns)\n",
    "for col in categorical_features:\n",
    "    X_kaggle_imp[col] = X_kaggle_imp[col].astype('category')\n",
    "\n",
    "numero_de_cliente = X_kaggle_imp['numero_de_cliente'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entranmiento con semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running semillerío para entrega\")\n",
    "print(params)\n",
    "\n",
    "# para registrar las probabilidades\n",
    "df_sem_proba = pd.DataFrame({\n",
    "                            'client': numero_de_cliente.values,\n",
    "                        })\n",
    "\n",
    "j = 0\n",
    "s_r = range(217163, 455783, 7*7*7*7*3) # 34 semillas\n",
    "s_r = list(range(2)) # 2 semillas de prueba\n",
    "\n",
    "s_total = len(list(s_r))\n",
    "for s in s_r:\n",
    "    # nueva instancia del modelos con semilla\n",
    "    seed = s + (7+j)\n",
    "    print(f\"Entrenando modelo con semilla: {seed}, {j+1} de {s_total}\")\n",
    "    # model = LGBMClassifier(**params, random_state=seed)\n",
    "    # # entreno\n",
    "    # model.fit(X=X_train_imp, y=y_train_binaria)\n",
    "\n",
    "    # seteo semilla\n",
    "    params.update({'seed': seed})\n",
    "    # training set\n",
    "    train_data = lgbm.Dataset(X_train_imp,\n",
    "                              label=y_train_binaria,\n",
    "                              weight=w_train)\n",
    "    model = lgbm.train(params,\n",
    "                       train_data,\n",
    "                       num_boost_round=1509) # best iteration de opt\n",
    "    \n",
    "    # predigo proba\n",
    "    y_pred_proba = model.predict_proba(X_kaggle_imp)\n",
    "    # proba baja+2\n",
    "    # proba_baja2 = y_pred_proba[:,2]\n",
    "    # proba baja\n",
    "    proba_baja = y_pred_proba[:,1]\n",
    "    df_sem_proba[f'proba_s{seed}'] = proba_baja\n",
    "    j += 1\n",
    "\n",
    "# Promediando proba de cada semilla\n",
    "proba_s_columns = df_sem_proba.filter(regex='^proba_s')\n",
    "proba_s_mean = proba_s_columns.mean(axis=1)\n",
    "\n",
    "df_sem_proba['proba_sem_mean'] = proba_s_mean\n",
    "\n",
    "# Umbral\n",
    "thr_opt_sem = 0.0195 # segun comp03_kaggle_api_sub\n",
    "\n",
    "# Segun Denicolay, el óptimo ronda los 11 mil estímulos\n",
    "\n",
    "# Prediccion\n",
    "df_sem_proba['pred'] = np.where(df_sem_proba.proba_sem_mean >= thr_opt_sem, 1, 0)\n",
    "\n",
    "df_sem_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'numero_de_cliente': numero_de_cliente.values,\n",
    "    'Predicted': df_sem_proba['pred'].values\n",
    "})\n",
    "\n",
    "# Imprimir value counts de las predicciones\n",
    "value_counts = submission['Predicted'].value_counts()\n",
    "total_count = len(submission)\n",
    "print(\"\\nValue Counts:\")\n",
    "print(value_counts)\n",
    "print(\"\\nFrecuencia Relativa:\")\n",
    "print((value_counts / total_count) * 100)\n",
    "\n",
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = \"%dT-%m-%Y%H-%M-%S\"\n",
    "t_now = datetime.datetime.now().strftime(ft)\n",
    "\n",
    "pred_name = f\"pred_sem_03_eug_sem{s_total}_\"+t_now+\".csv\"\n",
    "\n",
    "proba_file = pred_path + \"probas/\" + pred_name\n",
    "pred_file = pred_path + pred_name\n",
    "\n",
    "# Guardamos las probas\n",
    "df_sem_proba.to_csv(proba_file, index=False)\n",
    "print(f\"Probas guardadas en {proba_file}\")\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "submission.to_csv(pred_file, index=False)\n",
    "print(f\"Predicciones guardadas en {pred_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_eyf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
