{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNoCqM1I5-le"
   },
   "source": [
    "# Optimización Pipeline\n",
    "\n",
    "Incluye:\n",
    "\n",
    "- Tuning de hyperparámetros (con meses históricos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#######\n",
    "# rutas\n",
    "# datasets\n",
    "from config import dataset_file_fe6_6xpqt,\\\n",
    "                   dataset_file_fe6_6xpqt_opt_under\n",
    "# optimizacion\n",
    "from config import db_path\n",
    "# modelos\n",
    "from config import modelos_path\n",
    "# predicciones\n",
    "from config import pred_path\n",
    "\n",
    "\n",
    "##########\n",
    "# pipeline\n",
    "from processing import ModelPipeline\n",
    "from processing import analyze_study\n",
    "from sklearn.impute import SimpleImputer\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train_all = [201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
    "                 201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
    "                 202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_3_meses = [202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_6_meses = [202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_9_meses = [202010, 202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train_ult_anio = [202008, 202009, 202010, 202011, 202012, 202101, \n",
    "                      202102, 202103, 202104, 202105, 202106, 202107]\n",
    "\n",
    "mes_train = [202107]\n",
    "mes_test = 202109\n",
    "\n",
    "threshold = 0.025\n",
    "\n",
    "semillas = [437809, 327347, 392879, 455783, 217163]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM \n",
    "\n",
    "**Prepro in 6 months Conceptual FE 6 months + Lag1 + Delta1**\n",
    "\n",
    "> comp03_prepro_6x.ipynb\n",
    "\n",
    "> comp03_fe6_6x.ipynb\n",
    "\n",
    "**Usando los últimos 12 meses para optimizar** con 10 % de CONTINUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_parquet(dataset_file_fe6_6xpqt_opt_under)\n",
    "\n",
    "# running local\n",
    "data = pd.read_parquet(\"datos/datasets_competencia_03_fe6x_opt_under.parquet\")\n",
    "\n",
    "# Mapear etiquetas de clase a números\n",
    "label_mapping = {'CONTINUA': 0, 'BAJA+1': 1, 'BAJA+2': 2}\n",
    "\n",
    "data['clase_ternaria'] = data['clase_ternaria'].map(label_mapping)\n",
    "\n",
    "X_train = data[data['foto_mes'].isin(mes_train_ult_anio)]\n",
    "y_train = X_train['clase_ternaria']\n",
    "X_train = X_train.drop(columns=['clase_ternaria'])\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Corriendo pipeline con LightGBM ###\n",
      "Columns with all NaN values: ['payroll_slope_1_foto_mes', 'cuenta_corriente_slope_1_foto_mes', 'visa_consumo_slope_1_foto_mes', 'comisiones_mantenimiento_slope_1_foto_mes', 'comisiones_otras_slope_1_foto_mes']\n",
      "\n",
      "# Optimizando el modelo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 08:01:25,530] Using an existing study with name 'exp_lgbm_comp03_local_v00' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando lightgbm con 185 pruebas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 08:06:29,373] Trial 42 finished with value: 175618333.33333337 and parameters: {'n_estimators': 512, 'num_leaves': 71, 'learning_rate': 0.02037664360465537, 'min_data_in_leaf': 125, 'feature_fraction': 0.49270352148874796}. Best is trial 30 with value: 176340888.8888889.\n",
      "[I 2024-11-29 08:09:11,364] Trial 43 finished with value: 175445666.6666667 and parameters: {'n_estimators': 430, 'num_leaves': 52, 'learning_rate': 0.03856911907004415, 'min_data_in_leaf': 179, 'feature_fraction': 0.38876128102191915}. Best is trial 30 with value: 176340888.8888889.\n"
     ]
    }
   ],
   "source": [
    "# Condiciones de la optimización\n",
    "s = 1\n",
    "prepro = 6 # data quality + data drifting reducido\n",
    "fe = 6 # feature engineering conceptual 6 meses\n",
    "training = 12 # 12 meses de optimización con 10 % de CONTINUA\n",
    "\n",
    "print(\"### Corriendo pipeline con LightGBM ###\")\n",
    "# Inicializar el pipeline con 'lightgbm'\n",
    "pipeline_lgbm = ModelPipeline(data=None, seeds=semillas,\n",
    "                              model_type='lightgbm', seed=s, \n",
    "                              meses_opt=training, meses_test=1,\n",
    "                              threshold=0.015, # según back-testing en comp02\n",
    "                              n_jobs=-1)\n",
    "\n",
    "# Identify columns with all NaN values\n",
    "cols_with_all_nan = X_train.columns[X_train.isna().all()]\n",
    "print(\"Columns with all NaN values:\", cols_with_all_nan.tolist())\n",
    "\n",
    "# Drop these columns\n",
    "X_train = X_train.drop(columns=cols_with_all_nan) # extra limpieza\n",
    "\n",
    "# Imputación de valores faltantes\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_train_imp = pd.DataFrame(imp_median.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "del X_train\n",
    "\n",
    "# Codificar variables categóricas\n",
    "categorical_features = [col for col in X_train_imp.columns if X_train_imp[col].dtype == 'object']\n",
    "\n",
    "# Convertir variables categóricas a 'category' dtype para LightGBM\n",
    "for col in categorical_features:\n",
    "    X_train_imp[col] = X_train_imp[col].astype('category')\n",
    "\n",
    "# Definir el almacenamiento para Optuna\n",
    "# storage_name = \"sqlite:///\" + db_path + \"optimization_lgbm.db\"\n",
    "storage_name = \"sqlite:///optimizacion/optimization_tree.db\" # SUBIR a la nube para pipeline comp\n",
    "study_name = f\"exp_lgbm_comp03_local_v00\"\n",
    "\n",
    "print(\"\\n# Optimizando el modelo\")\n",
    "pipeline_lgbm.optimize_model(\n",
    "    X_train_imp, y_train,\n",
    "    storage_name=storage_name,\n",
    "    study_name=study_name,\n",
    "    optimize=True,\n",
    "    n_trials=185\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = analyze_study(storage_name, study_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dm_eyf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
