{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNoCqM1I5-le"
   },
   "source": [
    "# Back-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#######\n",
    "# rutas\n",
    "# datasets\n",
    "from config import dataset_file_fe6_6pqt\n",
    "# optimizacion\n",
    "from config import db_path\n",
    "# modelos\n",
    "from config import modelos_path\n",
    "# predicciones\n",
    "from config import pred_path\n",
    "\n",
    "##########\n",
    "# pipeline\n",
    "from processing import ModelPipeline, plot_comparisons_on_kaggle_split\n",
    "from processing import analyze_study\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "# Ignorar advertencias de tipo UserWarning\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='pandas')\n",
    "warnings.filterwarnings('ignore', category=Warning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=Warning, module='xgboost')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train_all = [201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
    "                 201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
    "                 202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106]\n",
    "\n",
    "mes_train_ult_3_meses = [202104, 202105, 202106]\n",
    "\n",
    "mes_train_ult_6_meses = [202101, 202102, 202103, 202104, 202105, 202106]\n",
    "\n",
    "mes_train_ult_9_meses = [202009, 202010, 202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106]\n",
    "\n",
    "mes_train_ult_anio = [202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106]\n",
    "\n",
    "mes_train = [202106]\n",
    "mes_test = 202108\n",
    "\n",
    "threshold = 0.025\n",
    "\n",
    "semillas = [437809, 327347, 392879, 455783, 217163]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IbyPo4Dk4Mdh"
   },
   "outputs": [],
   "source": [
    "# data = pd.read_parquet(dataset_file_fe6_6pqt)\n",
    "\n",
    "# running local\n",
    "data = pd.read_parquet(\"datos/datasets_competencia_02_fe6_6_6m_train.parquet\")\n",
    "\n",
    "# Mapear etiquetas de clase a números\n",
    "label_mapping = {'CONTINUA': 0, 'BAJA+1': 1, 'BAJA+2': 2}\n",
    "\n",
    "data['clase_ternaria'] = data['clase_ternaria'].map(label_mapping)\n",
    "\n",
    "# Simulación para Kaggle\n",
    "X_train = data[data['foto_mes'].isin([202101, 202102, 202103, 202104])]\n",
    "y_train = X_train['clase_ternaria']\n",
    "X_train = X_train.drop(columns=['clase_ternaria'])\n",
    "\n",
    "mes_futuro = 202106 # usado como test\n",
    "X_test = data[data['foto_mes'] == mes_futuro]\n",
    "y_test = X_test['clase_ternaria']\n",
    "X_test = X_test.drop(columns=['clase_ternaria'])\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesando data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with all NaN values: ['payroll_slope_1_foto_mes', 'cuenta_corriente_slope_1_foto_mes', 'visa_consumo_slope_1_foto_mes', 'comisiones_mantenimiento_slope_1_foto_mes', 'comisiones_otras_slope_1_foto_mes']\n"
     ]
    }
   ],
   "source": [
    "# Imputacion de Xs\n",
    "cols_with_all_nan = X_train.columns[X_train.isna().all()].tolist()\n",
    "print(\"Columns with all NaN values:\", cols_with_all_nan)\n",
    "X_train = X_train.drop(columns=cols_with_all_nan)\n",
    "X_test = X_test.drop(columns=cols_with_all_nan)\n",
    "\n",
    "# Imputación de nulls\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_train_imp = pd.DataFrame(imp_median.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imp = pd.DataFrame(imp_median.transform(X_test), columns=X_train.columns)\n",
    "\n",
    "del X_train\n",
    "del X_test\n",
    "\n",
    "# Codificar variables categóricas\n",
    "categorical_features = [col for col in X_train_imp.columns if X_train_imp[col].dtype == 'object']\n",
    "\n",
    "# Convertir variables categóricas a 'category' dtype para LightGBM\n",
    "for col in categorical_features:\n",
    "    X_train_imp[col] = X_train_imp[col].astype('category')\n",
    "    X_test_imp[col] = X_test_imp[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganancia(y, y_hat, thr, \n",
    "             ganancia_acierto = ganancia_acierto, \n",
    "             costo_estimulo = costo_estimulo,\n",
    "             target = 2, prop=1):\n",
    "\n",
    "    # Calcular la ganancia para cada fila\n",
    "    gains = np.where(y_hat >= thr, np.where(y == target, ganancia_acierto, -costo_estimulo), 0)\n",
    "\n",
    "    # Sumar las ganancias\n",
    "    estimated_gain = gains.sum()/prop\n",
    "\n",
    "    return estimated_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos candidatos\n",
    "\n",
    "Luego de una comparación de modelos candidatos en comp02_pipeline_comp\n",
    "\n",
    "Se decide optar como **modelo regular** el:\n",
    "\n",
    "> **xgb prepro6 fe6 y 3 opt (local opt)**\n",
    "\n",
    "Mientras que, para calcular una predicción con semillerío:\n",
    "\n",
    "Modelo **semillero de Denicolay** (modificado)\n",
    "\n",
    "semillerio_params = {'n_estimators': 23,\n",
    "                  'num_leaves': 32,\n",
    "                  'learning_rate': 0.34,\n",
    "                  'min_data_in_leaf': 711,\n",
    "                  'feature_fraction': 2*0.2, # x2 para tratar de compenzar la falta de variables\n",
    "                  'extra_trees': False,\n",
    "                  'random_state': semillas[s],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de semillerios \n",
    "\n",
    "Que incluya una nuevaa evaluación del punto de corte\n",
    "\n",
    "Aparte del hecho en comp02_back-testing\n",
    "\n",
    "Entrenamiento con óptimos parámetros\n",
    "\n",
    "**Modelo regular**\n",
    "\n",
    "Con las distintas semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(range(217163, 455783, 7*7*7*7*7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running back-testing for XGBClassifier Opt\n",
      "{'n_estimators': 464, 'max_leaves': 228, 'eta': 0.026841741174110256, 'gamma': 0.6065611085207565, 'min_child_weight': 10, 'subsample': 0.8649413237261332, 'colsample_bytree': 0.5013152719066779, 'n_jobs': -1}\n",
      "# Semillerio: 217163, 0 de 10\n",
      "Entrenando modelo con semilla: 217163, 0 de 25\n",
      "Entrenando modelo con semilla: 226767, 1 de 25\n",
      "Entrenando modelo con semilla: 236371, 2 de 25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# entreno\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando modelo con semilla: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m de \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_total\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_imp, y_train)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# predigo proba\u001b[39;00m\n\u001b[0;32m     55\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_imp)\n",
      "File \u001b[1;32mc:\\Users\\santt\\.conda\\envs\\dm_eyf\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\santt\\.conda\\envs\\dm_eyf\\Lib\\site-packages\\xgboost\\sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1529\u001b[0m )\n\u001b[1;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1532\u001b[0m     params,\n\u001b[0;32m   1533\u001b[0m     train_dmatrix,\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1535\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1536\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1537\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1538\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1539\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1540\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1541\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1542\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1543\u001b[0m )\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\santt\\.conda\\envs\\dm_eyf\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\santt\\.conda\\envs\\dm_eyf\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\santt\\.conda\\envs\\dm_eyf\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2102\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2103\u001b[0m         )\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Tomando al mejor modelo optimizado\n",
    "\n",
    "prepro = 6 # data quality + data drifting\n",
    "fe = 6 # feature engineering conceptual 6 meses\n",
    "training = 3 # un mes de optimización\n",
    "\n",
    "storage_name = \"sqlite:///\" + db_path + \"optimization_tree.db\"\n",
    "# carga local\n",
    "# storage_name = \"sqlite:///optimizacion/optimization_tree.db\"\n",
    "study_name = f\"exp_xgb_pr{prepro}_fe{fe}_tr{training}_x\"\n",
    "\n",
    "study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "\n",
    "# Mejores parámetros\n",
    "opt_params = study.best_trial.params\n",
    "opt_params.update({'n_jobs': -1})\n",
    "\n",
    "print(\"Running back-testing for XGBClassifier Opt\")\n",
    "print(opt_params)\n",
    "\n",
    "# para registrar las probabilidades\n",
    "df_s_proba = pd.DataFrame({\n",
    "                            'client': y_test.index,\n",
    "                            'baja': y_test.values,\n",
    "                        })\n",
    "\n",
    "label_antimapping = {0:'CONTINUA', 1:'BAJA+1', 2:'BAJA+2'}\n",
    "df_s_proba['clase_ternaria'] = df_s_proba['baja'].map(label_antimapping)\n",
    "\n",
    "df_xgb_semillerios = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "sem_total = 10\n",
    "s_total = 15\n",
    "for sem in range(217163, 455783, 7*7*7*7*10): # con 10 semillerios\n",
    "    print(f\"# Semillerio: {sem}, {i} de {sem_total}\")\n",
    "    semillerio = []\n",
    "    l_max_gan = []\n",
    "    l_max_gan_thr = []\n",
    "    l_max_gan_esti = []\n",
    "\n",
    "    # para operar sobre el semillerio\n",
    "    df_s = df_s_proba\n",
    "\n",
    "    j = 0\n",
    "    for s in range(217163, 455783, 7*7*7*7*7): # con 15 semillas por semillerio\n",
    "        # nueva instancia del modelos con semilla\n",
    "        seed = s+(7+j)**i\n",
    "        model = XGBClassifier(**opt_params, seed=seed)\n",
    "        # entreno\n",
    "        print(f\"Entrenando modelo con semilla: {seed}, {j+1} de {s_total}\")\n",
    "        model.fit(X_train_imp, y_train)\n",
    "        # predigo proba\n",
    "        y_pred_proba = model.predict_proba(X_test_imp)\n",
    "        # proba baja+2\n",
    "        proba_baja2 = y_pred_proba[:,2]\n",
    "        df_s[f'proba_s{seed}'] = proba_baja2\n",
    "        j += 1\n",
    "    \n",
    "    proba_s_columns = df_s.filter(regex='^proba_s')\n",
    "\n",
    "    proba_s_mean = proba_s_columns.mean(axis=1)\n",
    "\n",
    "    df_s['proba_sem_mean'] = proba_s_mean  \n",
    "\n",
    "    # dataframe con el test\n",
    "    test_results = pd.DataFrame({\n",
    "                            'client': y_test.index,\n",
    "                            'baja': y_test.values,\n",
    "                            'proba_sem_baja2' : df_s['proba_s_mean'].values\n",
    "                        })\n",
    "    test_results['clase_ternaria'] = test_results['baja'].map(label_antimapping)\n",
    "\n",
    "    # ganancias según threshold\n",
    "    thrs = []\n",
    "    ganancias = []\n",
    "    estimulos = []\n",
    "    for thr in np.linspace(0.01, 0.05, 100):\n",
    "        gain = ganancia(test_results.baja, test_results.proba_sem_baja2, thr)\n",
    "        esti = np.where(test_results.proba_sem_baja2 >= thr, 1, 0).sum()\n",
    "        thrs.append(thr)\n",
    "        ganancias.append(gain)\n",
    "        estimulos.append(esti)\n",
    "            \n",
    "    df_xgb_semillerios[f'threshold'] = thrs # será siempre igual\n",
    "    df_xgb_semillerios[f'ganancias_{sem}'] = ganancias # será siempre igual\n",
    "    df_xgb_semillerios[f'estimulos_{sem}'] = estimulos # será siempre igual\n",
    "\n",
    "    # maxima ganancia y condiciones\n",
    "    max_gan_idx = df_xgb_semillerios[f'ganancias_{sem}'].idxmax()\n",
    "    max_gan_thr = df_xgb_semillerios['threshold'][max_gan_idx]\n",
    "    max_gan = df_xgb_semillerios[f'ganancias_{sem}'][max_gan_idx]\n",
    "    max_estimulos = df_xgb_semillerios[f'estimulos_{sem}'][max_gan_idx]\n",
    "        \n",
    "    print(f\"sem: {sem}, ganancia max: {max_gan}, thr: {max_gan_thr}, estimulos: {max_estimulos}\")\n",
    "    \n",
    "    # registro condiciones de maxima para summary\n",
    "    semillerio.append(sem)\n",
    "    l_max_gan_thr.append(max_gan_thr)\n",
    "    l_max_gan.append(max_gan)\n",
    "    l_max_gan_esti.append(max_estimulos)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "\n",
    "df_xgb_semillerios_summary = pd.DataFrame({\n",
    "                            'semillerio': semillerio,\n",
    "                            'thr_max_gan': l_max_gan_thr,\n",
    "                            'max_gan': l_max_gan,\n",
    "                            'est_max_gan': l_max_gan_esti,\n",
    "                        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis del semillerio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb_semillerios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb_semillerios_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb_semillerios.to_csv('predicciones/df_xgb_semillerios.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ganancias_estimulos(df_sem):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Iterar sobre cada columna de ganancias y estimulos\n",
    "    for sem in df_sem.columns:\n",
    "        if sem.startswith('ganancias_'):\n",
    "            ganancias = df_sem[sem]\n",
    "            threshold = df_sem['threshold']\n",
    "            \n",
    "            # Plot A: Threshold vs Ganancias in gray\n",
    "            ax1.plot(threshold, ganancias, color='gray')\n",
    "\n",
    "    # Calcular y graficar las ganancias y estímulos promedio\n",
    "    ganancias_avg = df_sem[[col for col in df_sem.columns if col.startswith('ganancias_')]].mean(axis=1)\n",
    "    estimulos_avg = df_sem[[col for col in df_sem.columns if col.startswith('estimulos_')]].mean(axis=1)\n",
    "    \n",
    "    # Plot average in black\n",
    "    ax1.plot(threshold, ganancias_avg, label='Ganancias Promedio', color='black', linestyle='--')\n",
    "\n",
    "    # Highlight maximum gain\n",
    "    max_gain_idx = ganancias_avg.idxmax()\n",
    "    max_gain_threshold = threshold[max_gain_idx]\n",
    "    max_gain = max(ganancias_avg)\n",
    "    max_estimulos = estimulos_avg[max_gain_idx]\n",
    "\n",
    "    ax1.scatter(max_gain_threshold, max_gain, color='red', zorder=5)\n",
    "    ax1.annotate(f\"Max Gain: {max_gain}\\nThresh: {max_gain_threshold:.3f}\\nEstim: {max_estimulos}\", \n",
    "                (max_gain_threshold, max_gain), textcoords=\"offset points\", xytext=(0,-20), ha='center')\n",
    "\n",
    "    ax1.set_xlabel('Threshold')\n",
    "    ax1.set_ylabel('Ganancias')\n",
    "    ax1.legend()\n",
    "    plt.title('Ganancias vs Threshold para cada Semillerio')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ganancias_estimulos(df_xgb_semillerios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo semillero**\n",
    "\n",
    "Con las distintas semillas, según Denicolay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semillero_params = {'n_estimators': 23,\n",
    "                  'num_leaves': 32,\n",
    "                  'learning_rate': 0.34,\n",
    "                  'min_data_in_leaf': 711,\n",
    "                  'feature_fraction': 2*0.2, # x2 para tratar de compenzar la falta de variables\n",
    "                  'extra_trees': False,\n",
    "                  'random_state': semillas[s],\n",
    "}\n",
    "semillero_params.update({'n_jobs': -1})\n",
    "\n",
    "print(\"Running back-testing for Semillerio Denicolay\")\n",
    "print(semillero_params)\n",
    "\n",
    "# para registrar las probabilidades\n",
    "df_s_proba = pd.DataFrame({\n",
    "                            'client': y_test.index,\n",
    "                            'baja': y_test.values,\n",
    "                        })\n",
    "\n",
    "label_antimapping = {0:'CONTINUA', 1:'BAJA+1', 2:'BAJA+2'}\n",
    "df_s_proba['clase_ternaria'] = df_s_proba['baja'].map(label_antimapping)\n",
    "\n",
    "df_semillerios = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "sem_total = 10\n",
    "s_total = 15\n",
    "for sem in range(217163, 455783, 7*7*7*7*10): # con 10 semillerios\n",
    "    print(f\"# Semillerio: {sem}, {i} de {sem_total}\")\n",
    "    semillerio = []\n",
    "    l_max_gan = []\n",
    "    l_max_gan_thr = []\n",
    "    l_max_gan_esti = []\n",
    "\n",
    "    # para operar sobre el semillerio\n",
    "    df_s = df_s_proba\n",
    "\n",
    "    j = 0\n",
    "    for s in range(217163, 455783, 7*7*7*7*7): # con 15 semillas por semillerio\n",
    "        # nueva instancia del modelos con semilla\n",
    "        seed = s+(7+j)**i\n",
    "        model = XGBClassifier(**semillero_params, seed=seed)\n",
    "        # entreno\n",
    "        print(f\"Entrenando modelo con semilla: {seed}, {j} de {s_total}\")\n",
    "        model.fit(X_train_imp, y_train)\n",
    "        # predigo proba\n",
    "        y_pred_proba = model.predict_proba(X_test_imp)\n",
    "        # proba baja+2\n",
    "        proba_baja2 = y_pred_proba[:,2]\n",
    "        df_s[f'proba_s{seed}'] = proba_baja2\n",
    "        j += 1\n",
    "    \n",
    "    proba_s_columns = df_s.filter(regex='^proba_s')\n",
    "\n",
    "    proba_s_mean = proba_s_columns.mean(axis=1)\n",
    "\n",
    "    df_s['proba_sem_mean'] = proba_s_mean  \n",
    "\n",
    "    # dataframe con el test\n",
    "    test_results = pd.DataFrame({\n",
    "                            'client': y_test.index,\n",
    "                            'baja': y_test.values,\n",
    "                            'proba_sem_baja2' : df_s['proba_s_mean'].values\n",
    "                        })\n",
    "    test_results['clase_ternaria'] = test_results['baja'].map(label_antimapping)\n",
    "\n",
    "    # ganancias según threshold\n",
    "    thrs = []\n",
    "    ganancias = []\n",
    "    estimulos = []\n",
    "    for thr in np.linspace(0.01, 0.05, 100):\n",
    "        gain = ganancia(test_results.baja, test_results.proba_sem_baja2, thr)\n",
    "        esti = np.where(test_results.proba_sem_baja2 >= thr, 1, 0).sum()\n",
    "        thrs.append(thr)\n",
    "        ganancias.append(gain)\n",
    "        estimulos.append(esti)\n",
    "            \n",
    "    df_semillerios[f'threshold'] = thrs # será siempre igual\n",
    "    df_semillerios[f'ganancias_{sem}'] = ganancias # será siempre igual\n",
    "    df_semillerios[f'estimulos_{sem}'] = estimulos # será siempre igual\n",
    "\n",
    "    # maxima ganancia y condiciones\n",
    "    max_gan_idx = df_semillerios[f'ganancias_{sem}'].idxmax()\n",
    "    max_gan_thr = df_semillerios['threshold'][max_gan_idx]\n",
    "    max_gan = df_semillerios[f'ganancias_{sem}'][max_gan_idx]\n",
    "    max_estimulos = df_semillerios[f'estimulos_{sem}'][max_gan_idx]\n",
    "        \n",
    "    print(f\"sem: {sem}, ganancia max: {max_gan}, thr: {max_gan_thr}, estimulos: {max_estimulos}\")\n",
    "    \n",
    "    # registro condiciones de maxima para summary\n",
    "    semillerio.append(sem)\n",
    "    l_max_gan_thr.append(max_gan_thr)\n",
    "    l_max_gan.append(max_gan)\n",
    "    l_max_gan_esti.append(max_estimulos)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "df_semillerios_summary = pd.DataFrame({\n",
    "                            'semillerio': semillerio,\n",
    "                            'thr_max_gan': l_max_gan_thr,\n",
    "                            'max_gan': l_max_gan,\n",
    "                            'est_max_gan': l_max_gan_esti,\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semillerios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semillerios_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semillerios.to_csv('predicciones/df_profe_semillerios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ganancias_estimulos(df_semillerios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de semillerios\n",
    "\n",
    "Con métodos visuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ganancias_todas_superpuestas(df_sem1, df_sem2):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Colores y nombres para cada modelo\n",
    "    colores = ['blue', 'green']\n",
    "    modelos = [df_sem1, df_sem2]\n",
    "    nombres_modelos = ['xgb sem', 'denicolay sem']\n",
    "\n",
    "    for i, df_sem in enumerate(modelos):\n",
    "        color = colores[i]\n",
    "        nombre_modelo = nombres_modelos[i]\n",
    "        \n",
    "        # Obtener el threshold\n",
    "        threshold = df_sem['threshold']\n",
    "        \n",
    "        # Graficar ganancias individuales\n",
    "        for sem in df_sem.columns:\n",
    "            if sem.startswith('ganancias_'):\n",
    "                ganancias = df_sem[sem]\n",
    "                ax1.plot(threshold, ganancias, color=color, alpha=0.1)\n",
    "        \n",
    "        # Calcular y graficar las ganancias promedio\n",
    "        ganancias_cols = [col for col in df_sem.columns if col.startswith('ganancias_')]\n",
    "        ganancias_avg = df_sem[ganancias_cols].mean(axis=1)\n",
    "        ax1.plot(threshold, ganancias_avg, label=f'Ganancias Promedio {nombre_modelo}', color=color, linewidth=2)\n",
    "        \n",
    "        # Destacar la ganancia máxima\n",
    "        max_gain_idx = ganancias_avg.idxmax()\n",
    "        max_gain_threshold = threshold.iloc[max_gain_idx]\n",
    "        max_gain = ganancias_avg.iloc[max_gain_idx]\n",
    "        \n",
    "        ax1.scatter(max_gain_threshold, max_gain, color=color, zorder=5)\n",
    "        ax1.annotate(f\"Max Gain {nombre_modelo}: {max_gain:.2f}\\nThresh: {max_gain_threshold:.3f}\", \n",
    "                    (max_gain_threshold, max_gain), textcoords=\"offset points\", xytext=(0,-20*(i+1)), ha='center', color=color)\n",
    "\n",
    "    ax1.set_xlabel('Threshold')\n",
    "    ax1.set_ylabel('Ganancias')\n",
    "    ax1.legend()\n",
    "    plt.title('Comparación de Ganancias vs Threshold entre Modelos')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ganancias_todas_superpuestas(df_xgb_semillerios, df_semillerios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ganancias_promedio_superpuestas(df_sem1, df_sem2):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Colores y nombres para cada modelo\n",
    "    colores = ['blue', 'green']\n",
    "    modelos = [df_sem1, df_sem2]\n",
    "    nombres_modelos = ['xgb sem', 'denicolay sem']\n",
    "\n",
    "    for i, df_sem in enumerate(modelos):\n",
    "        color = colores[i]\n",
    "        nombre_modelo = nombres_modelos[i]\n",
    "        \n",
    "        # Obtener el threshold\n",
    "        threshold = df_sem['threshold']\n",
    "        \n",
    "        # Calcular las ganancias promedio\n",
    "        ganancias_cols = [col for col in df_sem.columns if col.startswith('ganancias_')]\n",
    "        ganancias_avg = df_sem[ganancias_cols].mean(axis=1)\n",
    "        \n",
    "        # Graficar las ganancias promedio\n",
    "        ax1.plot(threshold, ganancias_avg, label=f'Ganancias Promedio {nombre_modelo}', color=color)\n",
    "        \n",
    "        # Destacar la ganancia máxima\n",
    "        max_gain_idx = ganancias_avg.idxmax()\n",
    "        max_gain_threshold = threshold.iloc[max_gain_idx]\n",
    "        max_gain = ganancias_avg.iloc[max_gain_idx]\n",
    "        \n",
    "        ax1.scatter(max_gain_threshold, max_gain, color=color, zorder=5)\n",
    "        ax1.annotate(f\"Max Gain {nombre_modelo}: {max_gain:.2f}\\nThresh: {max_gain_threshold:.3f}\", \n",
    "                    (max_gain_threshold, max_gain), textcoords=\"offset points\", xytext=(0,-20*(i+1)), ha='center', color=color)\n",
    "\n",
    "    ax1.set_xlabel('Threshold')\n",
    "    ax1.set_ylabel('Ganancias Promedio')\n",
    "    ax1.legend()\n",
    "    plt.title('Comparación de Ganancias Promedio vs Threshold entre Modelos')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ganancias_promedio_superpuestas(df_xgb_semillerios, df_semillerios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dm_eyf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
