{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción para Kaggle\n",
    "\n",
    "Incluye:\n",
    "\n",
    "- Modelo optimizado, semilla única\n",
    "- Semillerío\n",
    "- Semillerío con modelo simplificado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import joblib\n",
    "\n",
    "####################\n",
    "# funciones y clases\n",
    "from utils import psi, drift_deflacion\n",
    "\n",
    "#######\n",
    "# rutas\n",
    "# datasets\n",
    "from config import dataset_file_fe6_6pqt\n",
    "# optimizacion\n",
    "from config import db_path\n",
    "# modelos\n",
    "from config import modelos_path\n",
    "# predicciones\n",
    "from config import pred_path\n",
    "\n",
    "##########\n",
    "# pipeline\n",
    "from processing import ModelPipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "##############\n",
    "# optimización\n",
    "import optuna\n",
    "\n",
    "#########\n",
    "# modelos\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignorar advertencias de tipo UserWarning\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='pandas')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train_all = [201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
    "                 201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
    "                 202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106]\n",
    "\n",
    "mes_train_ult_3_meses = [202104, 202105, 202106]\n",
    "\n",
    "mes_train_ult_6_meses = [202101, 202102, 202103, 202104, 202105, 202106]\n",
    "\n",
    "mes_train_ult_9_meses = [202009, 202010, 202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106]\n",
    "\n",
    "mes_train_ult_anio = [202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
    "                 202101, 202102, 202103, 202104, 202105, 202106]\n",
    "\n",
    "mes_train = [202106]\n",
    "mes_test = 202108\n",
    "\n",
    "threshold = 0.025\n",
    "\n",
    "semillas = [437809, 327347, 392879, 455783, 217163]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(dataset_file_fe6_6pqt)\n",
    "\n",
    "train_data = data[data['foto_mes'].isin(mes_train_ult_6_meses)]\n",
    "score_data = data[data['foto_mes'] == mes_test]\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesando data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_all_nan = train_data.columns[train_data.isna().all()]\n",
    "print(\"Columns with all NaN values:\", cols_with_all_nan.tolist())\n",
    "\n",
    "y_train = train_data['clase_ternaria']\n",
    "X_train = train_data.drop(columns=['clase_ternaria']+cols_with_all_nan)\n",
    "\n",
    "# Imputación de valores faltantes\n",
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_train_imp = pd.DataFrame(imp_median.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "del X_train\n",
    "\n",
    "# Opcional: Codificar variables categóricas\n",
    "# LightGBM puede manejar variables categóricas directamente si se especifican\n",
    "# Si tus datos tienen variables categóricas, puedes identificarlas y especificarlas en el modelo\n",
    "categorical_features = [col for col in X_train_imp.columns if X_train_imp[col].dtype == 'object']\n",
    "\n",
    "# Convertir variables categóricas a 'category' dtype para LightGBM\n",
    "for col in categorical_features:\n",
    "    X_train_imp[col] = X_train_imp[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepro in 6 months and Conceptual FE 6 months**\n",
    "\n",
    "> comp02_prepro_6.ipynb\n",
    "\n",
    "> comp02_fe6_6.ipynb\n",
    "\n",
    "**Usando los últimos 1 meses para optimizar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargando estudio de optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condiciones de la optimización\n",
    "s = 1\n",
    "prepro = 6 # data quality + data drifting\n",
    "fe = 6 # feature engineering conceptual 6 meses\n",
    "training = 1 # un mes de optimización\n",
    "\n",
    "# Definir el almacenamiento de Optuna\n",
    "storage_name = \"sqlite:///\" + db_path + \"optimization_lgbm.db\"\n",
    "study_name = f\"exp_lgbm_pr{prepro}_fe{fe}_tr{training}\"\n",
    "\n",
    "loaded_study = optuna.load_study(study_name = study_name,\n",
    "                                 storage = storage_name)\n",
    "\n",
    "# Mejores parámetros\n",
    "best_params = loaded_study.best_trial\n",
    "\n",
    "# Entrenamiento\n",
    "model = LGBMClassifier(**best_params)\n",
    "print(\"Entrenando modelo con:\")\n",
    "print(best_params)\n",
    "model.fit(X_train_imp, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = \"%dT-%m-%Y%H-%M-%S\"\n",
    "t_now = datetime.datetime.now().strftime(ft)\n",
    "\n",
    "model_name = f\"lgbm_pr{prepro}_fe{fe}_tr{training}\"+t_now\n",
    "\n",
    "model_path = modelos_path + model_name +\".pkl\"\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle = score_data\n",
    "\n",
    "del score_data\n",
    "\n",
    "# dropping variables según pipeline en train\n",
    "X_kaggle = X_kaggle.drop(columns=['clase_ternaria'] + cols_with_all_nan)\n",
    "\n",
    "# imputación usando último imputer ajustado con X_train\n",
    "X_kaggle_imp = pd.DataFrame(imp_median.transform(X_kaggle), columns=X_kaggle.columns)\n",
    "\n",
    "del X_kaggle\n",
    "\n",
    "# modificando tipo de variables según las categóricas del X_train\n",
    "for col in categorical_features:\n",
    "    X_kaggle_imp[col] = X_kaggle_imp[col].astype('category')\n",
    "\n",
    "numero_de_cliente = X_kaggle_imp['numero_de_cliente']\n",
    "\n",
    "# prediccion\n",
    "y_pred_proba = model.predict_proba(X_kaggle_imp)\n",
    "proba_baja2 = y_pred_proba[:,2]\n",
    "\n",
    "# umbral\n",
    "thr_opt_mean = 0.019367\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'numero_de_cliente': numero_de_cliente.values,\n",
    "    'Predicted': (proba_baja2['prediccion'] >= thr_opt_mean).astype(int)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando entrega simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = \"%dT-%m-%Y%H-%M-%S\"\n",
    "t_now = datetime.datetime.now().strftime(ft)\n",
    "\n",
    "pred_name = f\"lgbm_pr{prepro}_fe{fe}_tr{training}\"+t_now+\".csv\"\n",
    "\n",
    "pred_file = pred_path + pred_name\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "submission.to_csv(pred_file, index=False)\n",
    "print(f\"Predicciones guardadas en {pred_file}\")\n",
    "\n",
    "# Imprimir value counts de las predicciones\n",
    "value_counts = submission['Predicted'].value_counts()\n",
    "total_count = len(submission)\n",
    "print(\"\\nValue Counts:\")\n",
    "print(value_counts)\n",
    "print(\"\\nFrecuencia Relativa:\")\n",
    "print((value_counts / total_count) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semillerío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
